[
  {
    "objectID": "api.html",
    "href": "api.html",
    "title": "API for Programmatic Access",
    "section": "",
    "text": "APIs (Application Programming Interfaces) allow programmatic access to data resources. If you need to fetch and analyse metadata for many Samples, you can write a script to fetch data in this way.\nThe HoloFood Data Portal API gives programmatic access to the HoloFood Samples and their metadata, as well as URLs for where datasets are stored in public archives."
  },
  {
    "objectID": "api.html#canonical-urls",
    "href": "api.html#canonical-urls",
    "title": "API for Programmatic Access",
    "section": "Canonical URLs",
    "text": "Canonical URLs\nThroughout the API, canonical_urls are returned which point to the canonical database entry, i.e. the authoritative source, for each data object.\nThese are:\n\nThe European Nucleotide Archive Browser for Samples and Projects.\nMGnify for metagenomic-derived analyses and MAGs (metagenome assembled genomes)\nMetaboLights for metabolomic analyses\nThe websites of various partner institutions and registries where an IRI has been supplied with a metadata entry.\nThe HoloFood Data Portal itself for “Analysis Summaries”, which are documents hosted only by this website.\nThe HoloFood Data Portal itself for viral annotations"
  },
  {
    "objectID": "api.html#api-endpoints-and-playground",
    "href": "api.html#api-endpoints-and-playground",
    "title": "API for Programmatic Access",
    "section": "API Endpoints and Playground",
    "text": "API Endpoints and Playground\nThe “Browsable API Playground” is the best place to discover the API. Find this under the API navigation item on the data portal.\nThe browsable API lets you see the endpoints and their response schemas. Under an endpoint, press Try it out to see the output for a specific query.\nIn brief, the top-level endpoints are:\n\n/api/samples\nList samples, or fetch details about a specific sample (like its metadata). List all possible metadata markers (i.e. keys).\n\n\n/api/analysis-summaries\nList summary analyses published on the data portal.\n\n\n/api/genome-catalogues\nList MAG catalogues, or fetch detail about a catalogue, or list the MAGs within a catalogue.\n\n\n/api/viral-catalogues\nList Viral catalogues, or fetch detail about a catalogue, or list the fragments within a catalogue."
  },
  {
    "objectID": "api.html#using-the-api",
    "href": "api.html#using-the-api",
    "title": "API for Programmatic Access",
    "section": "Using the API",
    "text": "Using the API\n\nFrom the command line\nUse a command line tool like cURL to query the API. Responses are in JSON format.\nFor example to list all samples:\ncurl http://holofooddataportaldev-env.eba-jwzhg3z2.eu-west-1.elasticbeanstalk.com/api/samples\nTo find the Acetic acid metadata associated with sample SAMEA14099422, we could (using jq to handle JSON data on the command line):\ncurl http://holofooddataportaldev-env.eba-jwzhg3z2.eu-west-1.elasticbeanstalk.com/api/samples/SAMEA14099422 | jq '.structured_metadata | .[] | select(.marker.name == \"Acetic acid\")'\nand get\n{\n  \"marker\": {\n    \"name\": \"Acetic acid\",\n    \"type\": \"FATTY ACIDS\",\n    \"canonical_url\": null\n  },\n  \"measurement\": \"62.30155\",\n  \"units\": \"umol/g digesta\"\n}\n\n\nFrom Python\nMore realistically, to fetch a list of samples as a Pandas dataframe\n\n\n\n\n\n\nPackages required\n\n\n\npip install requests pandas\n\n\n\nimport requests\nimport pandas as pd\n\nsamples = requests.get('http://holofooddataportaldev-env.eba-jwzhg3z2.eu-west-1.elasticbeanstalk.com/api/samples')\n\nsamples_df = pd.json_normalize(samples.json()['items'])\nsamples_df.head(3)\n\n\n\n\n\n  \n    \n      \n      accession\n      title\n      system\n      has_metagenomics\n      canonical_url\n      metagenomics_url\n      project.accession\n      project.title\n      project.canonical_url\n    \n  \n  \n    \n      0\n      SAMEA14099422\n      CB03.16F1a\n      chicken\n      False\n      https://www.ebi.ac.uk/ena/browser/view/SAMEA14...\n      None\n      PRJEB39110\n      HoloFood Chicken - MAG Catalogue from Caecum c...\n      https://www.ebi.ac.uk/ena/browser/view/PRJEB39110\n    \n    \n      1\n      SAMEA7025234\n      CA01.10F1a\n      chicken\n      False\n      https://www.ebi.ac.uk/ena/browser/view/SAMEA70...\n      None\n      PRJEB39110\n      HoloFood Chicken - MAG Catalogue from Caecum c...\n      https://www.ebi.ac.uk/ena/browser/view/PRJEB39110\n    \n    \n      2\n      SAMEA7025235\n      CA02.14F1a\n      chicken\n      False\n      https://www.ebi.ac.uk/ena/browser/view/SAMEA70...\n      None\n      PRJEB39110\n      HoloFood Chicken - MAG Catalogue from Caecum c...\n      https://www.ebi.ac.uk/ena/browser/view/PRJEB39110\n    \n  \n\n\n\n\n\n\n\n\n\n\nPaginated data\n\n\n\nHowever… we haven’t got all of the data. We only have one page.\nThe ?page= URL query parameter lets us retrieve subsequent pages.\n\n\n\nlen(samples_df)\n\n100\n\n\nThe API response does tell us how many items there are in total:\n\nsamples.json()['count']\n\n429\n\n\nsamples_endpoint_base = 'http://holofooddataportaldev-env.eba-jwzhg3z2.eu-west-1.elasticbeanstalk.com/api/samples'\n\npage = 1\n\nwhile page:\n    print(f'Fetching {page=}')\n    \n    samples_page = requests.get(f'{samples_endpoint_base}?{page=}').json()\n    samples_page_df = pd.json_normalize(samples_page['items'])\n    \n    if page == 1:\n        samples_df = samples_page_df\n    else:\n        samples_df = pd.concat([samples_df, samples_page_df])\n    page += 1\n    if len(samples_df) >= samples_page['count']:\n        page = False\n\nFetching page=1\nFetching page=2\nFetching page=3\nFetching page=4\nFetching page=5\n\n\n\nlen(samples_df)\n\n429\n\n\n\nFind all salmon samples:\n\nsalmon = samples_df[samples_df.system == 'salmon']\nprint(len(salmon))\nsalmon.head(3)\n\n359\n\n\n\n\n\n\n  \n    \n      \n      accession\n      title\n      system\n      has_metagenomics\n      canonical_url\n      metagenomics_url\n      project.accession\n      project.title\n      project.canonical_url\n    \n  \n  \n    \n      68\n      SAMEA7678309\n      SA01.05C1a\n      salmon\n      False\n      https://www.ebi.ac.uk/ena/browser/view/SAMEA76...\n      None\n      PRJEB41657\n      HoloFood Salmon - Metagenomic DNA\n      https://www.ebi.ac.uk/ena/browser/view/PRJEB41657\n    \n    \n      69\n      SAMEA7678310\n      SB10.13C1a\n      salmon\n      False\n      https://www.ebi.ac.uk/ena/browser/view/SAMEA76...\n      None\n      PRJEB41657\n      HoloFood Salmon - Metagenomic DNA\n      https://www.ebi.ac.uk/ena/browser/view/PRJEB41657\n    \n    \n      70\n      SAMEA7687880\n      SA01.01C1a\n      salmon\n      False\n      https://www.ebi.ac.uk/ena/browser/view/SAMEA76...\n      None\n      PRJEB41657\n      HoloFood Salmon - Metagenomic DNA\n      https://www.ebi.ac.uk/ena/browser/view/PRJEB41657"
  },
  {
    "objectID": "api.html#filters-using-query-parameters",
    "href": "api.html#filters-using-query-parameters",
    "title": "API for Programmatic Access",
    "section": "Filters using query parameters",
    "text": "Filters using query parameters\nWe didn’t need to fetch all the samples to then select only the Salmon ones. We can instead fetch only the salmon ones using a query parameter filter. (If you’re familiar with SQL, this eventually maps to a WHERE clause on the database.)\n\npage = 1\n\nwhile page:\n    print(f'Fetching {page=}')\n    \n    salmon_page = requests.get(f'{samples_endpoint_base}?{page=}&system=salmon').json()\n    salmon_page_df = pd.json_normalize(salmon_page['items'])\n    \n    if page == 1:\n        salmon_df = salmon_page_df\n    else:\n        salmon_df = pd.concat([salmon_df, salmon_page_df])\n    page += 1\n    if len(salmon_df) >= salmon_page['count']:\n        page = False\n\nFetching page=1\nFetching page=2\nFetching page=3\nFetching page=4\n\n\nAnd so, we’ve more efficiently fetched the same set of (salmon) samples:\n\nsalmon_df.size == samples_df[samples_df.system == 'salmon'].size\n\nTrue"
  },
  {
    "objectID": "tutorial.html",
    "href": "tutorial.html",
    "title": "Tutorial",
    "section": "",
    "text": "This tutorial showcases the core uses of the Data Portal. There is a solution to each learning objective.\n\n\nOpen the HoloFood Data Portal.\nFind all Salmon samples from the project PRJEB41657.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nClick Salmon samples in the navigation bar.\nType PRJEB41657 into the Project accession contains filter next to the table, and press Apply.\n\n\n\n\n\n\n\n\nFind the Chicken sample SAMEA7025251.\nFrom the sample’s metadata, find the average daily feed intake of chicken’s in that pen in the first trial week.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nClick Chicken samples in the navigation bar.\nType SAMEA7025251 into the Accession contains filter, press Apply.\nClick View in the single row of the table.\nOpen the Sample metadata section of the sample detail page.\nSwitch to the Pen tab of metadata.\nFind the Average Daily Feed intake: Day 00 - 07 row (measurement = 18.59g).\n\n\n\n\n\n\n\n\nFind chicken sample SAMEA7817177 on the data portal\nFollow the links to the sample’s metagenomics analyses on MGnify\nWhat is SAMEA7817177’s top Pfam entry (from MGnify’s functional analysis of it)?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nType SAMEA7817177 into the Search data and docs search bar at the top of the data portal\nThe sample detail page for SAMEA7817177 will open directly\nOpen the Metagenomics section of the sample detail page.\nClick the assembly analysis in the table\nOn MGnify, switch to the Functional analysis tab.\nFind the Pfam subtab\nFind the first row of the table (the biggest bar in the bar chart)\nIt is Reverse transcriptase PF07727\n\n\n\n\n\n\n\n\n\n\n\n\n\nNot HoloFood Data\n\n\n\nCurrently this example is based on data that does not originate from the HoloFood project. HoloFood MAG Catalogues will be available soon.\n\n\n\nFind the (Not HoloFood) Cow Rumen v1 genome MGYG000290023\nUsing the genome’s species representative, find the genome’s most prevalent COG category with a known function.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nClick Genomes in the navigation bar.\nSelect the (Not HoloFood) Cow Rumen v1 catalogue in the sub navigation\nType MGYG000290023 in the Accession contains filter.\n\nYou could also jump straight to here by entering the accession in the global search box\n\nClick View on MGnify in the single row of the table.\nOn the MGnify page that opens, switch to the COG analysis sub-tab.\nLook at the bar chart. Ignoring cataegory S (Function unknown), category M (Cell wall/membrane/envelope biogenesis) is the most prevalent COG category in this genome.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFake data\n\n\n\nCurrently this example is based on fake data that does not originate from the HoloFood project. Real HoloFood Viral Catalogues will be available soon.\n\n\n\nFind the HoloFood Cow Rumen Viruses v0 catalogue`\nFind a viral sequence present in the host MAG with taxonomy Prevotella sp902792635\nFind all of the ViPhOG viral annotations on that viral sequence\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nClick Viruses in the navigation bar.\nSelect the HoloFood Cow Rumen Viruses v0 catalogue in the sub navigation\nType Prevotella sp902792635 in the Host MAG taxonomy contains filter.\nClick View contig in the first/only row of the table.\nIn the contig viewer now shown above the table, find the ViPhOGs annotation track\nClick on each ViPhOG annotation (dark green), and find the ViPhOG ID from the popup\nYou should have found two: [ViPhOG1, ViPhOG2]\n\n\n\n\n\n\n\n\nFind chicken sample SAMEA14099422 on the data portal, and download the sample’s metadata TSV file\nDo the same for sample SAMEA7025235\nNotice that the samples are from chickens in different pens, fed different diets (Control, and Probioticrespectively)\nPick a spreadsheet application like Google Sheets, Excel, or LibreOffice Calc, (or write some code)\nMake a plot comparing the average weight gain of chickens in each of the two pens over time\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nOpen the Chicken samples navigation item\nType SAMEA14099422 into the Accession contains filter and press Apply\nClick View in the only row in the table\nScroll down and open the Sample metadata section\nPress Download all as TSV\nRename the downloaded file (metadata.tsv) to something useful like control.tsv\nRepeat the previous steps for SAMEA7025235, getting to a file called e.g. probiotic.tsv\nOpen/import both files in your spreadsheet application\nFind the rows labelled Average body weight at day 00.....35\nCopy and paste the rows from each sheet next to each other\nIn Google Sheets, press Insert > Chart (or similar in other applications)\n\n\n\n\nScreenshot of spreadsheet chart comparing average weight of chickens in two pens fed Control and Probiotic diets respectively\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoding required\n\n\n\nThis objective takes a lot longer than the others – it involves coding and the API.\n\n\n\n\n\n\n\n\nPackages required\n\n\n\npip install requests pandas matplotlib\n\n\n\nUse the API to fetch a list of HoloFood samples as a Pandas dataframe (the API docs will be very helpful)\n\nOnly fetch samples from project PRJEB41657\nOnly fetch samples from Trial A Tank 1 (which happen to have sample titles starting SA01)\nOnly fetch samples which have a non-empty value for metadata variable host length (that’s the length of the fish the sample came from)\n\nMake two histograms, showing the distribution of host length metadata values at timepoints 0 days and 60 days\n\nHere’s a startpoint for the libraries and base API endpoint you need:\nsamples_endpoint_base = 'http://holofooddataportaldev-env.eba-jwzhg3z2.eu-west-1.elasticbeanstalk.com/api/samples'\nimport requests\nimport pandas as pd\nimport matplotlib.pyplot as plt\nA complete solution is below.\n\n\nCode\npage = 1\n\nwhile page:\n    samples_page = requests.get(\n        f'{samples_endpoint_base}?{page=}&project=PRJEB41657&title=SA01&require_metadata_value=host length'\n    ).json()\n    samples_page_df = pd.json_normalize(\n        samples_page['items']\n    )\n    \n    if page == 1:\n        samples_df = samples_page_df\n    else:\n        samples_df = pd.concat(\n            [\n                samples_df,\n                samples_page_df\n            ]\n        )\n    \n    page += 1\n    if len(samples_df) >= samples_page['count']:\n        page = False\n\ndef get_host_length_and_timepoint(sample):\n    sample_detail = requests.get(\n        f'{samples_endpoint_base}/{sample.accession}'\n    ).json()\n    metadata = sample_detail['structured_metadata']\n    host_length = next(\n        metadatum \n        for metadatum in metadata \n        if metadatum['marker']['name'] == 'host length'\n    )\n    timepoint = next(\n        metadatum \n        for metadatum in metadata \n        if metadatum['marker']['name'] == 'trial timepoint'\n    )\n    return host_length['measurement'], timepoint['measurement']\n\nmetadata = samples_df.apply(\n    get_host_length_and_timepoint, \n    axis='columns', \n    result_type='expand'\n).rename(\n    columns={\n        0: 'host_length_cm', \n        1: 'trial_timepoint_days'\n    }\n)\ntrial_samples = pd.concat(\n    [\n        samples_df,\n        metadata\n    ]\n)\ntrial_samples.groupby('trial_timepoint_days').host_length_cm.hist(legend=True, bins=5, alpha=0.5)\nplt.xlabel('Host length / cm');"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HoloFood Data Portal",
    "section": "",
    "text": "The database and website to present Holofood samples, and unify the datasets stored in supporting services."
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "HoloFood Data Portal",
    "section": "Background",
    "text": "Background\nHoloFood is a consortium and project focussed on understanding the biomolecular and physiological processes triggered by incorporating feed additives and novel sustainable feeds in farmed animals.\nThe data portal is a public website and API for browsing the Samples and datasets created by the project, which are stored in publicly-accessible data repositories.\n\n\n\nDiagram of HoloFood data flow"
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "All HoloFood samples are registered in the European Nucleotide Archive, which has extensive documentation.\nMost analyses of the samples are stored in further appropriate supporting databases, with a small number hosted directly in the HoloFood data portal."
  },
  {
    "objectID": "datasets.html#ena-studies-projects",
    "href": "datasets.html#ena-studies-projects",
    "title": "Datasets",
    "section": "ENA Studies (Projects)",
    "text": "ENA Studies (Projects)\nAn ENA Study (or Project) is part of the ENA Metadata Model. > A study (project) groups together data submitted to the archive and controls its release date. A study accession is typically used when citing data submitted to ENA."
  },
  {
    "objectID": "datasets.html#ena-samples",
    "href": "datasets.html#ena-samples",
    "title": "Datasets",
    "section": "ENA Samples",
    "text": "ENA Samples\nAn ENA Sample is part of the ENA Metadata Model. > A sample contains information about the sequenced source material. Samples are associated with checklists, which define the fields used to annotate the samples."
  },
  {
    "objectID": "datasets.html#ena-checklist-metadata",
    "href": "datasets.html#ena-checklist-metadata",
    "title": "Datasets",
    "section": "ENA Checklist Metadata",
    "text": "ENA Checklist Metadata\nAn ENA Checklist is a set of metadata (some mandatory) for a given sample type.\nThe HoloFood checklist is ERC000052."
  },
  {
    "objectID": "datasets.html#biosamples-metadata",
    "href": "datasets.html#biosamples-metadata",
    "title": "Datasets",
    "section": "BioSamples Metadata",
    "text": "BioSamples Metadata\nBioSamples is an EBI service hosting annotations keyed against an existing sample hosted elsewhere (in HoloFood’s case, ENA). For HoloFood biosamples, these are registered against a specific ontology.\nThe majority of HoloFood samples’ metadata are hosted in BioSamples.\nThere is a BioSamples online training course to learn more."
  },
  {
    "objectID": "datasets.html#mgnify-metagenomics",
    "href": "datasets.html#mgnify-metagenomics",
    "title": "Datasets",
    "section": "MGnify: Metagenomics",
    "text": "MGnify: Metagenomics\nMetagenomic-derived analyses are available for some HoloFood samples.\nThese datasets and analysis features are hosted by MGnify, which also has extensive documentation.\n\nMGnify is a freely available hub for the analysis and exploration of metagenomic, metatranscriptomic, amplicon and assembly data.\n\n\nMetagenome Assembled Genome (MAG) Catalogues\nMAG Catalogues are available for selected biomes. MAGs are draft genomes created by binning assembled metagenomic reads. These MAGs are created using the MGnify Genomes Pipeline. MAGs are annotated using various functional and taxonomic characterisation tools.\nHoloFood MAGs are those created using only reads from HoloFood samples. However, there are other non-HoloFood public data available for the same biomes sampled by this project.\nEach HoloFood MAG Catalogue therefore referenced a public MAG Catalogue in MGnify, which is a superset of the HoloFood data and other public data.\nEach MAG in the HoloFood catalogue references a MAG in the MGnify catalogue which represents the same species. In some cases, the HoloFood MAG is the best available sequence for that species level cluster, so the HoloFood MAG points to itself on the MGnify website. In other cases, a more complete, less contaminated, or isolate genome exists representing the same species, so the HoloFood MAG points to this better representative on MGnify.\n\n\nViral (fragment) Catalogues\nViral catalogues are lists of the unique (at species-level) viruses found in HoloFood samples. Viral sequences are detected using VIRify. Viruses are shown as fragments (regions) of the parent contigs in which they were found. The contigs are those stored in MGnify, from the HoloFood Sample sequencing. Annotations are available on the contigs from the MGnify analysis pipeline."
  },
  {
    "objectID": "datasets.html#metabolights-metabolomics",
    "href": "datasets.html#metabolights-metabolomics",
    "title": "Datasets",
    "section": "MetaboLights: Metabolomics",
    "text": "MetaboLights: Metabolomics\nMetabolomics-derived analyses are available for some HoloFood samples.\nThese datasets are hosted by MetaboLights."
  },
  {
    "objectID": "datasets.html#summary-analyses",
    "href": "datasets.html#summary-analyses",
    "title": "Datasets",
    "section": "Summary analyses",
    "text": "Summary analyses\nSummary analyses are higher level analyses of a Sample or collection of Samples; written documents serving as short analysis summaries.\nThese summaries are hosted directly by the HoloFood data portal.\nThe documents are written by HoloFood partners and moderated by the HoloFood consortium, but are not peer-reviewed research articles.\nEach analysis summary is linked to one or more Samples that were included in the analysis or are relevant to it."
  },
  {
    "objectID": "website.html",
    "href": "website.html",
    "title": "Browsing the website",
    "section": "",
    "text": "Screenshot of the global search box\n\n\nThere is a a site-wide (“global”) search box at the top of the data portal landing page and most other pages. This searches over project accession and titles; sample systems, accessions, and titles; genome and viral catalogue ids, titles, biomes, and related data; MAG accessions and taxonomies; viral fragment ids and contig ids; and this documentation.\nIf you search for valid sample, project, or MAG accessions, the search will take you straight to an appropriate view in the portal. Otherwise, you’ll see a normal list of search results."
  },
  {
    "objectID": "website.html#finding-samples",
    "href": "website.html#finding-samples",
    "title": "Browsing the website",
    "section": "Finding Samples",
    "text": "Finding Samples\n\n\n\nScreenshot of sample listing webpage\n\n\nSamples can be found from the “Chicken samples” and “Salmon samples” navigation items. On the samples listing pages, there are various filters available to limit which samples are shown in the table. For example, you can find all samples from a particular project, or all samples with metabolomics data.\nThe table shows an icon-key detailing which data types are available for each sample. Samples may be linked to metadata (almost always), metagenomic, or metabolomic datasets.\nTo view detail about a particular sample, click “View” on its row of the table.\nThe sample detail page contains information help about the sample in the various supporting databases. Metadata is shown in full, in a table. Metagenomic and metabolomic data are shown in summary form, with links to the respective public websites where those analyses are held.\nThe API section shows the API endpoint for this particular sample. You can copy this into a script, for example, to programmatically pull the data."
  },
  {
    "objectID": "website.html#downloading-sample-lists-and-metadata",
    "href": "website.html#downloading-sample-lists-and-metadata",
    "title": "Browsing the website",
    "section": "Downloading sample lists and metadata",
    "text": "Downloading sample lists and metadata\nThe complete sample list can be exported to TSV using the “Download all as TSV” button.\n\n\n\n\n\n\nNote\n\n\n\nThe “Download all as TSV” button does reflect any filters on the website table – it contains the complete list.\n\n\n\n\n\nScreenshot of a sample detail page with TSV export option\n\n\nThe complete metadata for a sample can be downloaded using the “Download all as TSV” button within the “Sample metadata” section of a sample detail page."
  },
  {
    "objectID": "website.html#finding-sample-data-in-other-public-repositories",
    "href": "website.html#finding-sample-data-in-other-public-repositories",
    "title": "Browsing the website",
    "section": "Finding sample data in other public repositories",
    "text": "Finding sample data in other public repositories\n\nMetagenomics\nSome samples have metagenomics data, in MGnify. These can be found from the samples listing page by setting the Has metagenomics filter to Yes.\nMGnify analyses of a sample (identified with MGYA accessions) are listed and linked to from the sample detail page.\n\n\n\nScreenshot of a sample detail page with metagenomics data\n\n\n\n\nMetabolomics\nSome other samples have metabolomics data, in MetaboLights. These can be found form the samples listing page by setting the Has metabolomics filter to Yes.\nMetaboLights data are identified at a Project level, with MTBLS accessions. MetaboLights does not store samples as independent objects, instead it stores lists of samples and files (and more) for the project. So, the HoloFood data portal sample detail page shows a filtered table of the MetaboLights project’s files, that relate to this sample. Following these file links will download the file.\n\n\n\nScreenshot of a sample detail page with metabolomics data"
  },
  {
    "objectID": "website.html#finding-analysis-summaries",
    "href": "website.html#finding-analysis-summaries",
    "title": "Browsing the website",
    "section": "Finding analysis summaries",
    "text": "Finding analysis summaries\n\n\n\nScreenshot of a sample detail page with analysis documents links\n\n\nAnalysis summaries are linked to samples (or whole projects). Any analysis summaries that mention a sample, or its project, are shown at the bottom of the sample’s detail page.\n\n\n\nScreenshot of an analysis document\n\n\nAnalysis summaries also link back to the samples and/or projects they refer to. A complete list of analysis summaries can also be found from the navigation bar."
  },
  {
    "objectID": "website.html#using-the-catalogues",
    "href": "website.html#using-the-catalogues",
    "title": "Browsing the website",
    "section": "Using the catalogues",
    "text": "Using the catalogues\n\nMAG Catalogues\nMetagenome Assembled Genome (MAG) Catalogues are available for selected biomes. HoloFood MAGs are those created using only reads from HoloFood samples. However, there are other non-HoloFood public data available for the same biomes sampled by this project.\nEach HoloFood MAG Catalogue therefore referenced a public MAG Catalogue in MGnify, which is a superset of the HoloFood data and other public data. This is linked from each catalogue page on the HoloFood Data Portal site.\nEach MAG in the HoloFood catalogue references a MAG in the MGnify catalogue which represents the same species. In some cases, the HoloFood MAG is the best available sequence for that species level cluster, so the HoloFood MAG points to itself on the MGnify website. In other cases, a more complete, less contaminated, or isolate genome exists representing the same species, so the HoloFood MAG points to this better representative on MGnify.\n\n\n\nScreenshot of a MAG catalogue\n\n\nMAG Catalogues can be found from the “Genomes” navigation item, and then selecting a catalogue in the “Catalogues” sub-navigation. MAGs can be found by searching on accession or taxonomy, or for the accession of the cluster representative.\nThe MAGs in a catalogue can be downloaded as a TSV file, using the “Download all as TSV” button.\n\n\nViral Catalogues\n Viral catalogues are lists of the unique (at species-level) viruses found in HoloFood samples. Viral catalogues can be found from the “Viruses” navigation item, and then selecting a catalogue in the “Catalogues” sub-navigation.\nViral fragment can be searched in various ways, like the parent contig ID, or the taxonomy of the host MAG. Host MAGs are only assigned where there is an exact match between the viral sequence and a host MAG.\nBy default, only species-level clusters are shown (a representative viral fragment is shown).\nThis can be changed either by clicking the “View cluster” link within the table, to see the remainder of that specific cluster, or by changing the “Cluster visibility” dropdown in the filters to the left of the table.\nPressing “View contig” on a viral fragment in the table opens the contig viewer. This loads the contig from MGnify, as well as MGnify’s annotations on the contig. These can be explored in more detail by clicking the parent contig in the table, which links to MGnify.\nIn the contig viewer, ViPhOG annotations are shown. These are unique to the data portal. The viral region is highlighted in green. The GFF containing the ViPhOG(s) can also be downloaded, by viewing a viral fragment and pressing “Download ViPhOGs GFF”."
  },
  {
    "objectID": "partners.html",
    "href": "partners.html",
    "title": "Admin access for HoloFood partners",
    "section": "",
    "text": "Bulk activities, like importing projects, samples, and metadata, are covered in the repository README.\nThere is also an Admin Panel where individual database entries can be managed."
  },
  {
    "objectID": "partners.html#authoring-new-summary-analysis-documents",
    "href": "partners.html#authoring-new-summary-analysis-documents",
    "title": "Admin access for HoloFood partners",
    "section": "Authoring new Summary Analysis documents",
    "text": "Authoring new Summary Analysis documents\nNavigate to the site admin panel, and log in.\n\n\n\n\n\n\nTip\n\n\n\nIf you do not have the link or credentials, please contact the helpdesk.\n\n\n\n\n\nScreenshot of admin panel landing page\n\n\nClick “Add” on the “Analysis Summary” entry. Depending on your permission level, you may see different objects than shown in the screenshot.\n\n\n\nScreenshot of an analysis summary in edit mode\n\n\nAnalysis summaries require a title (which is automatically converted into the URL slug). The document itself can be written as Markdown. To include images, upload them to a hosting site or GitHub repository, and include them via their URL. There are toolbar buttons in the markdown editor to help you with this syntax.\n\n\n\nScreenshot of a sample summary in edit mode\n\n\nAnalysis summaries must be linked to samples and/or projects and/or catalogues. To link them, select the relevant samples/projects/catalogues from the lists on the left, and hit the -> button to move the selected samples/projects/catalogues to the right-hand list.\n\n\n\n\n\n\nWarning\n\n\n\nDon’t forget to press “Save and continue editing” now and then!"
  },
  {
    "objectID": "partners.html#editing-and-publishing-summary-analysis-documents",
    "href": "partners.html#editing-and-publishing-summary-analysis-documents",
    "title": "Admin access for HoloFood partners",
    "section": "Editing and publishing Summary Analysis documents",
    "text": "Editing and publishing Summary Analysis documents\nSuperuser credentials are required to publish analysis summaries. Until published, the documents do not appear on the public website. As a superuser, tick the “Is published” checkbox on an analysis summary edit page in the admin panel, and press Save.\nIf you believe you should have superuser credentials, contact the helpdesk."
  }
]