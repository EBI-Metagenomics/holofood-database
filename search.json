[
  {
    "objectID": "website.html",
    "href": "website.html",
    "title": "Browsing the website",
    "section": "",
    "text": "Samples can be found from the “Chicken samples” and “Salmon samples” navigation items. On the samples listing pages, there are various filters available to limit which samples are shown in the table. For example, you can find all samples from a particular project, or all samples with metabolomics data.\nThe table shows an icon-key detailing which data types are available for each sample. Samples may be linked to metadata (almost always), metagenomic, or metabolomic datasets.\nTo view detail about a particular sample, click “View” on its row of the table.\nThe sample detail page contains information help about the sample in the various supporting databases. Metadata is shown in full, in a table. Metagenomic and metabolomic data are shown in summary form, with links to the respective public websites where those analyses are held.\nThe API section shows the API endpoint for this particular sample. You can copy this into a script, for example, to programmatically pull the data."
  },
  {
    "objectID": "website.html#mag-catalogues",
    "href": "website.html#mag-catalogues",
    "title": "Browsing the website",
    "section": "MAG Catalogues",
    "text": "MAG Catalogues\nMetagenome Assembled Genome (MAG) Catalogues are available for selected biomes. HoloFood MAGs are those created using only reads from HoloFood samples. However, there are other non-HoloFood public data available for the same biomes sampled by this project.\nEach HoloFood MAG Catalogue therefore referenced a public MAG Catalogue in MGnify, which is a superset of the HoloFood data and other public data. This is linked from each catalogue page on the HoloFood Data Portal site.\nEach MAG in the HoloFood catalogue references a MAG in the MGnify catalogue which represents the same species. In some cases, the HoloFood MAG is the best available sequence for that species level cluster, so the HoloFood MAG points to itself on the MGnify website. In other cases, a more complete, less contaminated, or isolate genome exists representing the same species, so the HoloFood MAG points to this better representative on MGnify.\n\n\n\nScreenshot of a MAG catalogue\n\n\nMAG Catalogues can be found from the “Genomes” navigation item, and then selecting a catalogue in the “Catalogues” sub-navigation. MAGs can be found by searching on accession or taxonomy, or for the accession of the cluster representative.\nThe MAGs in a catalogue can be downloaded as a TSV file, using the “Download all as TSV” button."
  },
  {
    "objectID": "website.html#viral-catalogues",
    "href": "website.html#viral-catalogues",
    "title": "Browsing the website",
    "section": "Viral Catalogues",
    "text": "Viral Catalogues\n Viral catalogues are lists of the unique (at species-level) viruses found in HoloFood samples. Viral catalogues can be found from the “Viruses” navigation item, and then selecting a catalogue in the “Catalogues” sub-navigation.\nViral fragment can be searched in various ways, like the parent contig ID, or the taxonomy of the host MAG. Host MAGs are only assigned where there is an exact match between the viral sequence and a host MAG.\nBy default, only species-level clusters are shown (a representative viral fragment is shown).\nThis can be changed either by clicking the “View cluster” link within the table, to see the remainder of that specific cluster, or by changing the “Cluster visibility” dropdown in the filters to the left of the table.\nPressing “View contig” on a viral fragment in the table opens the contig viewer. This loads the contig from MGnify, as well as MGnify’s annotations on the contig. These can be explored in more detail by clicking the parent contig in the table, which links to MGnify.\nIn the contig viewer, ViPhOG annotations are shown. These are unique to the data portal. The viral region is highlighted in green. The GFF containing the ViPhOG(s) can also be downloaded, by viewing a viral fragment and pressing “Download ViPhOGs GFF”."
  },
  {
    "objectID": "partners.html",
    "href": "partners.html",
    "title": "Admin access for HoloFood partners",
    "section": "",
    "text": "Bulk activities, like importing projects, samples, and metadata, are covered in the repository README.\nThere is also an Admin Panel where individual database entries can be managed."
  },
  {
    "objectID": "partners.html#authoring-new-summary-analysis-documents",
    "href": "partners.html#authoring-new-summary-analysis-documents",
    "title": "Admin access for HoloFood partners",
    "section": "Authoring new Summary Analysis documents",
    "text": "Authoring new Summary Analysis documents\nNavigate to the site admin panel, and log in.\n\n\n\n\n\n\nTip\n\n\n\nIf you do not have the link or credentials, please contact the helpdesk.\n\n\n Click “Add” on the “Sample annotation” entry. Depending on your permission level, you may see different objects than shown in the screenshot.\n Analysis summaries require a title (which is automatically converted into the URL slug). The document itself can be written as Markdown. To include images, upload them to a hosting site or GitHub repository, and include them via their URL. There are toolbar buttons in the markdown editor to help you with this syntax.\n Analysis summaries must be linked to samples and/or entire projects. To link them, select the relevant samples and/or projects from the lists on the left, and hit the -> button to move the selected samples/projects to the right-hand list.\n\n\n\n\n\n\nWarning\n\n\n\nDon’t forget to press “Save and continue editing” now and then!"
  },
  {
    "objectID": "partners.html#editing-and-publishing-summary-analysis-documents",
    "href": "partners.html#editing-and-publishing-summary-analysis-documents",
    "title": "Admin access for HoloFood partners",
    "section": "Editing and publishing Summary Analysis documents",
    "text": "Editing and publishing Summary Analysis documents\nSuperuser credentials are required to publish analysis summaries. Until published, the documents do not appear on the public website. As a superuser, tick the “Is published” checkbox on an analysis summary edit page in the admin panel, and press Save.\nIf you believe you should have superuser credentials, contact the helpdesk."
  },
  {
    "objectID": "tutorial.html",
    "href": "tutorial.html",
    "title": "Tutorial",
    "section": "",
    "text": "This tutorial showcases the core uses of the Data Portal. There is a solution to each learning objective.\n\n\nOpen the HoloFood Data Portal.\nFind all Salmon samples from the project PRJEB41657.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nType PRJEB41657 into the Project accession contains filter next to the table, and press Apply.\n\n\n\n\n\n\n\nFind the Chicken sample SAMEA7025251.\nFrom the sample’s metadata, find the average daily feed intake of chicken’s in that pen in the first trial week.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nClick Chicken samples in the navigation bar.\nType SAMEA7025251 into the Accession contains filter, press Apply.\nClick View in the single row of the table.\nOpen the Sample metadata section of the sample detail page.\nSwitch to the Pen tab of metadata.\nFind the Average Daily Feed intake: Day 00 - 07 row (measurement = 18.59g).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFake data\n\n\n\nCurrently this example is based on fake data that does not originate from the HoloFood project.\n\n\n\nFind the HoloFood Cow Rumen v1 genome MGYG1\nUsing the genome’s species representative, find the genome’s most prevalent COG category with a known function.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nClick Genomes in the navigation bar.\nSelect the HoloFood Cow Rumen v1 catalogue in the sub navigation\nType MGYG1 in the Accession contains filter.\nClick View on MGnify in the single row of the table.\nOn the MGnify page that opens, switch to the COG analysis sub-tab.\nLook at the bar chart. Ignoring cataegory S (Function unknown), category M (Cell wall/membrane/envelope biogenesis) is the most prevalent COG category in this genome.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFake data\n\n\n\nCurrently this example is based on fake data that does not originate from the HoloFood project.\n\n\n\nFind the HoloFood Cow Rumen Viruses v0 catalogue`\nFind a viral sequence present in the host MAG with taxonomy Prevotella sp902792635\nFind all of the ViPhOG viral annotations on that viral sequence\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nClick Viruses in the navigation bar.\nSelect the HoloFood Cow Rumen Viruses v0 catalogue in the sub navigation\nType Prevotella sp902792635 in the Host MAG taxonomy contains filter.\nClick View contig in the first/only row of the table.\nIn the contig viewer now shown above the table, find the ViPhOGs annotation track\nClick on each ViPhOG annotation (dark green), and find the ViPhOG ID from the popup\nYou should have found two: [ViPhOG1, ViPhOG2]\n\n\n\n\n\n\n\n\n\n\n\n\n\nPackages required\n\n\n\npip install requests pandas matplotlib\n\n\n\nUse the API to fetch a list of HoloFood samples as a Pandas dataframe (the API docs will be very helpful)\n\nOnly fetch samples from project PRJEB41657\nOnly fetch samples from Trial A Tank 1 (which happen to have sample titles starting SA01)\nOnly fetch samples which have a non-empty value for metadata variable host length (that’s the length of the fish the sample came from)\n\nMake two histograms, showing the distribution of host length metadata values at timepoints 0 days and 60 days\n\nHere’s a startpoint for the libraries and base API endpoint you need:\nsamples_endpoint_base = 'http://holofooddataportaldev-env.eba-jwzhg3z2.eu-west-1.elasticbeanstalk.com/api/samples'\nimport requests\nimport pandas as pd\nimport matplotlib as plt\nA complete solution is below.\n\n\nCode\npage = 1\n\nwhile page:\n    samples_page = requests.get(\n        f'{samples_endpoint_base}?{page=}&project=PRJEB41657&title=SA01&require_metadata_value=host length'\n    ).json()\n    samples_page_df = pd.json_normalize(\n        samples_page['items']\n    )\n    \n    if page == 1:\n        samples_df = samples_page_df\n    else:\n        samples_df = pd.concat(\n            [\n                samples_df,\n                samples_page_df\n            ]\n        )\n    \n    page += 1\n    if len(samples_df) >= samples_page['count']:\n        page = False\n\ndef get_host_length_and_timepoint(sample):\n    sample_detail = requests.get(\n        f'{samples_endpoint_base}/{sample.accession}'\n    ).json()\n    metadata = sample_detail['structured_metadata']\n    host_length = next(\n        metadatum \n        for metadatum in metadata \n        if metadatum['marker']['name'] == 'host length'\n    )\n    timepoint = next(\n        metadatum \n        for metadatum in metadata \n        if metadatum['marker']['name'] == 'trial timepoint'\n    )\n    return host_length['measurement'], timepoint['measurement']\n\nmetadata = samples_df.apply(\n    get_host_length_and_timepoint, \n    axis='columns', \n    result_type='expand'\n).rename(\n    columns={\n        0: 'host_length_cm', \n        1: 'trial_timepoint_days'\n    }\n)\ntrial_samples = pd.concat(\n    [\n        samples_df,\n        metadata\n    ]\n)\ntrial_samples.groupby('trial_timepoint_days').host_length_cm.hist(legend=True, bins=5, alpha=0.5)\nplt.xlabel('Host length / cm');"
  },
  {
    "objectID": "api.html",
    "href": "api.html",
    "title": "API for Programmatic Access",
    "section": "",
    "text": "APIs (Application Programming Interfaces) allow programmatic access to data resources. If you need to fetch and analyse metadata for many Samples, you can write a script to fetch data in this way.\nThe HoloFood Data Portal API gives programmatic access to the HoloFood Samples and their metadata, as well as URLs for where datasets are stored in public archives."
  },
  {
    "objectID": "api.html#canonical-urls",
    "href": "api.html#canonical-urls",
    "title": "API for Programmatic Access",
    "section": "Canonical URLs",
    "text": "Canonical URLs\nThroughout the API, canonical_urls are returned which point to the canonical database entry, i.e. the authoritative source, for each data object.\nThese are:\n\nThe European Nucleotide Archive Browser for Samples and Projects.\nMGnify for metagenomic-derived analyses and MAGs (metagenome assembled genomes)\nMetaboLights for metabolomic analyses\nThe websites of various partner institutions and registries where an IRI has been supplied with a metadata entry.\nThe HoloFood Data Portal itself for “Annotations”, which are documents hosted only by this website.\nThe HoloFood Data Portal itself for viral annotations"
  },
  {
    "objectID": "api.html#api-endpoints-and-playground",
    "href": "api.html#api-endpoints-and-playground",
    "title": "API for Programmatic Access",
    "section": "API Endpoints and Playground",
    "text": "API Endpoints and Playground\nThe “Browsable API Playground” is the best place to discover the API. Find this under the API navigation item on the data portal.\nThe browsable API lets you see the endpoints and their response schemas. Under an endpoint, press Try it out to see the output for a specific query.\nIn brief, the top-level endpoints are:\n\n/api/samples\nList samples, or fetch details about a specific sample (like its metadata). List all possible metadata markers (i.e. keys).\n\n\n/api/annotations\nList summary analyses published on the data portal.\n\n\n/api/genome-catalogues\nList MAG catalogues, or fetch detail about a catalogue, or list the MAGs within a catalogue.\n\n\n/api/viral-catalogues\nList Viral catalogues, or fetch detail about a catalogue, or list the fragments within a catalogue."
  },
  {
    "objectID": "api.html#using-the-api",
    "href": "api.html#using-the-api",
    "title": "API for Programmatic Access",
    "section": "Using the API",
    "text": "Using the API\n\nFrom the command line\nUse a command line tool like cURL to query the API. Responses are in JSON format.\nFor example to list all samples:\ncurl http://holofooddataportaldev-env.eba-jwzhg3z2.eu-west-1.elasticbeanstalk.com/api/samples\nTo find the Acetic acid metadata associated with sample SAMEA14099422, we could (using jq to handle JSON data on the command line):\ncurl http://holofooddataportaldev-env.eba-jwzhg3z2.eu-west-1.elasticbeanstalk.com/api/samples/SAMEA14099422 | jq '.structured_metadata | .[] | select(.marker.name == \"Acetic acid\")'\nand get\n{\n  \"marker\": {\n    \"name\": \"Acetic acid\",\n    \"type\": \"FATTY ACIDS\",\n    \"canonical_url\": null\n  },\n  \"measurement\": \"62.30155\",\n  \"units\": \"umol/g digesta\"\n}\n\n\nFrom Python\nMore realistically, to fetch a list of samples as a Pandas dataframe\n\n\n\n\n\n\nPackages required\n\n\n\npip install requests pandas\n\n\n\nimport requests\nimport pandas as pd\n\nsamples = requests.get('http://holofooddataportaldev-env.eba-jwzhg3z2.eu-west-1.elasticbeanstalk.com/api/samples')\n\nsamples_df = pd.json_normalize(samples.json()['items'])\nsamples_df.head(3)\n\n\n\n\n\n  \n    \n      \n      accession\n      title\n      system\n      has_metagenomics\n      canonical_url\n      metagenomics_url\n      project.accession\n      project.title\n      project.canonical_url\n    \n  \n  \n    \n      0\n      SAMEA14099422\n      CB03.16F1a\n      chicken\n      False\n      https://www.ebi.ac.uk/ena/browser/view/SAMEA14...\n      None\n      PRJEB39110\n      HoloFood Chicken - MAG Catalogue from Caecum c...\n      https://www.ebi.ac.uk/ena/browser/view/PRJEB39110\n    \n    \n      1\n      SAMEA7025234\n      CA01.10F1a\n      chicken\n      False\n      https://www.ebi.ac.uk/ena/browser/view/SAMEA70...\n      None\n      PRJEB39110\n      HoloFood Chicken - MAG Catalogue from Caecum c...\n      https://www.ebi.ac.uk/ena/browser/view/PRJEB39110\n    \n    \n      2\n      SAMEA7025235\n      CA02.14F1a\n      chicken\n      False\n      https://www.ebi.ac.uk/ena/browser/view/SAMEA70...\n      None\n      PRJEB39110\n      HoloFood Chicken - MAG Catalogue from Caecum c...\n      https://www.ebi.ac.uk/ena/browser/view/PRJEB39110\n    \n  \n\n\n\n\n\n\n\n\n\n\nPaginated data\n\n\n\nHowever… we haven’t got all of the data. We only have one page.\nThe ?page= URL query parameter lets us retrieve subsequent pages.\n\n\n\nlen(samples_df)\n\n100\n\n\nThe API response does tell us how many items there are in total:\n\nsamples.json()['count']\n\n429\n\n\nsamples_endpoint_base = 'http://holofooddataportaldev-env.eba-jwzhg3z2.eu-west-1.elasticbeanstalk.com/api/samples'\n\npage = 1\n\nwhile page:\n    print(f'Fetching {page=}')\n    \n    samples_page = requests.get(f'{samples_endpoint_base}?{page=}').json()\n    samples_page_df = pd.json_normalize(samples_page['items'])\n    \n    if page == 1:\n        samples_df = samples_page_df\n    else:\n        samples_df = pd.concat([samples_df, samples_page_df])\n    page += 1\n    if len(samples_df) >= samples_page['count']:\n        page = False\n\nFetching page=1\nFetching page=2\nFetching page=3\nFetching page=4\nFetching page=5\n\n\n\nlen(samples_df)\n\n429\n\n\n\nFind all salmon samples:\n\nsalmon = samples_df[samples_df.system == 'salmon']\nprint(len(salmon))\nsalmon.head(3)\n\n359\n\n\n\n\n\n\n  \n    \n      \n      accession\n      title\n      system\n      has_metagenomics\n      canonical_url\n      metagenomics_url\n      project.accession\n      project.title\n      project.canonical_url\n    \n  \n  \n    \n      68\n      SAMEA7678309\n      SA01.05C1a\n      salmon\n      False\n      https://www.ebi.ac.uk/ena/browser/view/SAMEA76...\n      None\n      PRJEB41657\n      HoloFood Salmon - Metagenomic DNA\n      https://www.ebi.ac.uk/ena/browser/view/PRJEB41657\n    \n    \n      69\n      SAMEA7678310\n      SB10.13C1a\n      salmon\n      False\n      https://www.ebi.ac.uk/ena/browser/view/SAMEA76...\n      None\n      PRJEB41657\n      HoloFood Salmon - Metagenomic DNA\n      https://www.ebi.ac.uk/ena/browser/view/PRJEB41657\n    \n    \n      70\n      SAMEA7687880\n      SA01.01C1a\n      salmon\n      False\n      https://www.ebi.ac.uk/ena/browser/view/SAMEA76...\n      None\n      PRJEB41657\n      HoloFood Salmon - Metagenomic DNA\n      https://www.ebi.ac.uk/ena/browser/view/PRJEB41657"
  },
  {
    "objectID": "api.html#filters-using-query-parameters",
    "href": "api.html#filters-using-query-parameters",
    "title": "API for Programmatic Access",
    "section": "Filters using query parameters",
    "text": "Filters using query parameters\nWe didn’t need to fetch all the samples to then select only the Salmon ones. We can instead fetch only the salmon ones using a query parameter filter. (If you’re familiar with SQL, this eventually maps to a WHERE clause on the database.)\n\npage = 1\n\nwhile page:\n    print(f'Fetching {page=}')\n    \n    salmon_page = requests.get(f'{samples_endpoint_base}?{page=}&system=salmon').json()\n    salmon_page_df = pd.json_normalize(salmon_page['items'])\n    \n    if page == 1:\n        salmon_df = salmon_page_df\n    else:\n        salmon_df = pd.concat([salmon_df, salmon_page_df])\n    page += 1\n    if len(salmon_df) >= salmon_page['count']:\n        page = False\n\nFetching page=1\nFetching page=2\nFetching page=3\nFetching page=4\n\n\nAnd so, we’ve more efficiently fetched the same set of (salmon) samples:\n\nsalmon_df.size == samples_df[samples_df.system == 'salmon'].size\n\nTrue"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HoloFood Data Portal",
    "section": "",
    "text": "Background\nHoloFood is a consortium and project focussed on understanding the biomolecular and physiological processes triggered by incorporating feed additives and novel sustainable feeds in farmed animals.\nThe data portal is a public website and API for browsing the Samples and datasets created by the project, which are stored in publicly-accessible data repositories."
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "All HoloFood samples are registered in the European Nucleotide Archive, which has extensive documentation.\nMost analyses of the samples are stored in further appropriate supporting databases, with a small number hosted directly in the HoloFood data portal."
  },
  {
    "objectID": "datasets.html#ena-studies-projects",
    "href": "datasets.html#ena-studies-projects",
    "title": "Datasets",
    "section": "ENA Studies (Projects)",
    "text": "ENA Studies (Projects)\nAn ENA Study (or Project) is part of the ENA Metadata Model. > A study (project) groups together data submitted to the archive and controls its release date. A study accession is typically used when citing data submitted to ENA."
  },
  {
    "objectID": "datasets.html#ena-samples",
    "href": "datasets.html#ena-samples",
    "title": "Datasets",
    "section": "ENA Samples",
    "text": "ENA Samples\nAn ENA Sample is part of the ENA Metadata Model. > A sample contains information about the sequenced source material. Samples are associated with checklists, which define the fields used to annotate the samples."
  },
  {
    "objectID": "datasets.html#ena-checklist-metadata",
    "href": "datasets.html#ena-checklist-metadata",
    "title": "Datasets",
    "section": "ENA Checklist Metadata",
    "text": "ENA Checklist Metadata\nAn ENA Checklist is a set of metadata (some mandatory) for a given sample type.\nThe HoloFood checklist is ERC000052."
  },
  {
    "objectID": "datasets.html#biosamples-metadata",
    "href": "datasets.html#biosamples-metadata",
    "title": "Datasets",
    "section": "BioSamples Metadata",
    "text": "BioSamples Metadata\nBioSamples is an EBI service hosting annotations keyed against an existing sample hosted elsewhere (in HoloFood’s case, ENA). For HoloFood biosamples, these are registered against a specific ontology.\nThe majority of HoloFood samples’ metadata are hosted in BioSamples.\nThere is a BioSamples online training course to learn more."
  },
  {
    "objectID": "datasets.html#mgnify-metagenomics",
    "href": "datasets.html#mgnify-metagenomics",
    "title": "Datasets",
    "section": "MGnify: Metagenomics",
    "text": "MGnify: Metagenomics\nMetagenomic-derived analyses are available for some HoloFood samples.\nThese datasets and analysis features are hosted by MGnify, which also has extensive documentation.\n\nMGnify is a freely available hub for the analysis and exploration of metagenomic, metatranscriptomic, amplicon and assembly data.\n\n\nMetagenome Assembled Genome (MAG) Catalogues\nMAG Catalogues are available for selected biomes. MAGs are draft genomes created by binning assembled metagenomic reads. These MAGs are created using the MGnify Genomes Pipeline. MAGs are annotated using various functional and taxonomic characterisation tools.\nHoloFood MAGs are those created using only reads from HoloFood samples. However, there are other non-HoloFood public data available for the same biomes sampled by this project.\nEach HoloFood MAG Catalogue therefore referenced a public MAG Catalogue in MGnify, which is a superset of the HoloFood data and other public data.\nEach MAG in the HoloFood catalogue references a MAG in the MGnify catalogue which represents the same species. In some cases, the HoloFood MAG is the best available sequence for that species level cluster, so the HoloFood MAG points to itself on the MGnify website. In other cases, a more complete, less contaminated, or isolate genome exists representing the same species, so the HoloFood MAG points to this better representative on MGnify.\n\n\nViral (fragment) Catalogues\nViral catalogues are lists of the unique (at species-level) viruses found in HoloFood samples. Viral sequences are detected using VIRify. Viruses are shown as fragments (regions) of the parent contigs in which they were found. The contigs are those stored in MGnify, from the HoloFood Sample sequencing. Annotations are available on the contigs from the MGnify analysis pipeline."
  },
  {
    "objectID": "datasets.html#metabolights-metabolomics",
    "href": "datasets.html#metabolights-metabolomics",
    "title": "Datasets",
    "section": "MetaboLights: Metabolomics",
    "text": "MetaboLights: Metabolomics\nMetabolomics-derived analyses are available for some HoloFood samples.\nThese datasets are hosted by MetaboLights."
  },
  {
    "objectID": "datasets.html#summary-analyses",
    "href": "datasets.html#summary-analyses",
    "title": "Datasets",
    "section": "Summary analyses",
    "text": "Summary analyses\nSummary analyses are higher level analyses of a Sample or collection of Samples; written documents serving as short analysis summaries.\nThese summaries are hosted directly by the HoloFood data portal.\nThe documents are written by HoloFood partners and moderated by the HoloFood consortium, but are not peer-reviewed research articles.\nEach analysis summary is linked to one or more Samples that were included in the analysis or are relevant to it."
  }
]